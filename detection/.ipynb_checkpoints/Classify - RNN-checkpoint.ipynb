{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import analyse\n",
    "from datetime import datetime as dt\n",
    "from cnn_load_data import load_labels as old_load_labels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Template code to refer to later\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "\n",
    "\n",
    "class SeriesPredictor:\n",
    "\n",
    "    def __init__(self, input_dim, seq_size, hidden_dim=10):\n",
    "        # Hyperparameters\n",
    "        self.input_dim = input_dim\n",
    "        self.seq_size = seq_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Weight variables and input placeholders\n",
    "        self.W_out = tf.Variable(tf.random_normal([hidden_dim, 1]), name='W_out')\n",
    "        self.b_out = tf.Variable(tf.random_normal([1]), name='b_out')\n",
    "        self.x = tf.placeholder(tf.float32, [None, seq_size, input_dim])\n",
    "        self.y = tf.placeholder(tf.float32, [None, seq_size])\n",
    "\n",
    "        # Cost optimizer\n",
    "        self.cost = tf.reduce_mean(tf.square(self.model() - self.y))\n",
    "        self.train_op = tf.train.AdamOptimizer().minimize(self.cost)\n",
    "\n",
    "        # Auxiliary ops\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "    def model(self):\n",
    "        \n",
    "        ##:param x: inputs of size [T, batch_size, input_size]\n",
    "        ##:param W: matrix of fully-connected output layer weights\n",
    "        ##:param b: vector of fully-connected output layer biases\n",
    "        \n",
    "        cell = rnn_cell.BasicLSTMCell(self.hidden_dim, reuse=tf.get_variable_scope().reuse)\n",
    "        outputs, states = rnn.dynamic_rnn(cell, self.x, dtype=tf.float32)\n",
    "        num_examples = tf.shape(self.x)[0]\n",
    "        W_repeated = tf.tile(tf.expand_dims(self.W_out, 0), [num_examples, 1, 1])\n",
    "        out = tf.batch_matmul(outputs, W_repeated) + self.b_out\n",
    "        out = tf.squeeze(out)\n",
    "        return out\n",
    "\n",
    "    def train(self, train_x, train_y):\n",
    "        with tf.Session() as sess:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            for i in range(1000):\n",
    "                _, mse = sess.run([self.train_op, self.cost], feed_dict={self.x: train_x, self.y: train_y})\n",
    "                if i % 100 == 0:\n",
    "                    print(i, mse)\n",
    "            save_path = self.saver.save(sess, 'model.ckpt')\n",
    "            print('Model saved to {}'.format(save_path))\n",
    "\n",
    "    def test(self, test_x):\n",
    "        with tf.Session() as sess:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            self.saver.restore(sess, 'model.ckpt')\n",
    "            output = sess.run(self.model(), feed_dict={self.x: test_x})\n",
    "            print(output)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    predictor = SeriesPredictor(input_dim=1, seq_size=4, hidden_dim=10)\n",
    "    train_x = [[[1], [2], [5], [6]],\n",
    "               [[5], [7], [7], [8]],\n",
    "               [[3], [4], [5], [7]]]\n",
    "    train_y = [[1, 3, 7, 11],\n",
    "               [5, 12, 14, 15],\n",
    "               [3, 7, 9, 12]]\n",
    "    predictor.train(train_x, train_y)\n",
    "\n",
    "    test_x = [[[1], [2], [3], [4]],  # 1, 3, 5, 7\n",
    "              [[4], [5], [6], [7]]]  # 4, 9, 11, 13\n",
    "    predictor.test(test_x)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnnClassify:\n",
    "    def __init__(self, n_classes=2, hm_epochs=25, keep_rate=0.8):\n",
    "        self.n_classes = n_classes\n",
    "        self.hm_epochs = hm_epochs\n",
    "        self.keep_rate = keep_rate\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        # Weight variables and input placeholders\n",
    "        self.x = tf.placeholder(tf.float32, [24, 24, 3])\n",
    "        self.y = tf.placeholder(tf.float32)\n",
    "        self.weights = {'W_conv1':tf.Variable(tf.random_normal([5,5,3,32]),name='W_conv1'),\n",
    "                        'W_conv2':tf.Variable(tf.random_normal([5,5,32,64]),name='W_conv2'),\n",
    "                        'W_fc':tf.Variable(tf.random_normal([6*6*64, 1024]),name='W_fc'),\n",
    "                        'W_out':tf.Variable(tf.random_normal([1024, self.n_classes]),name='W_out')}\n",
    "    \n",
    "        self.biases = {'b_conv1':tf.Variable(tf.random_normal([32]),name='b_conv1'),\n",
    "                       'b_conv2':tf.Variable(tf.random_normal([64]),name='b_conv2'),\n",
    "                       'b_fc':tf.Variable(tf.random_normal([1024]),name='b_fc'),\n",
    "                       'b_out':tf.Variable(tf.random_normal([self.n_classes]),name='b_out')}\n",
    "        \n",
    "        # Cost optimizer\n",
    "        self.cost = tf.reduce_mean(tf.square(self.rnn_model() - self.y))\n",
    "        self.train_op = tf.train.AdamOptimizer().minimize(self.cost)\n",
    "\n",
    "        # Auxiliary ops\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "    def frame_stamp(self):\n",
    "        current = dt.now()\n",
    "        out_str = (str(current.year) + str(current.month) + str(current.day) + \"_\" + \n",
    "                   str(current.hour) + str(current.minute) + str(current.second) + \"_\" +\n",
    "                   str(current.microsecond))\n",
    "        return out_str\n",
    "\n",
    "    def pad(self, arr):\n",
    "        r = np.zeros((24,24,3))\n",
    "        r[:arr.shape[0],:arr.shape[1],:arr.shape[2]] = arr\n",
    "        return r\n",
    "\n",
    "    def split_arr(self, arr, percent):\n",
    "        position = int(len(arr) * (1-percent))\n",
    "        train_data = arr[:position]\n",
    "        test_data = arr[position:]\n",
    "        return train_data, test_data\n",
    "    \n",
    "    def load_labels(self):\n",
    "        fdir = \"seq_labels\"\n",
    "        dataset = []\n",
    "        count = 0\n",
    "        none_count = 0\n",
    "        last_frame = 0\n",
    "        last_seq = 0\n",
    "        for file in os.listdir(fdir):\n",
    "            if file.endswith(\".jpg\"):\n",
    "                img = cv.imread(os.path.join(fdir,file), cv.IMREAD_UNCHANGED)\n",
    "                if not img is None:\n",
    "                    img = pad(img)\n",
    "                    file_params = file.split(\"_\")                \n",
    "                    ## Check if labeled as ball\n",
    "                    tmp_dataset = []\n",
    "                    if file_params[0] == 0:    \n",
    "                        tmp_dataset.append(img) #0\n",
    "                        tmp_dataset.append(np.array([0,1])) #1\n",
    "                    else:\n",
    "                        tmp_dataset.append(img) #0\n",
    "                        tmp_dataset.append(np.array([1,0])) #1\n",
    "                    ## Get seqence ID\n",
    "                    current_seq = int(file_params[1])\n",
    "                    tmp_dataset.append(current_seq) #2\n",
    "                    if current_seq != last_seq:\n",
    "                        last_frame = 0\n",
    "                        last_seq = current_seq\n",
    "\n",
    "                    ## Get frame number (Will decide if frame number or difference is more useful later on)\n",
    "                    print(file_params[2])\n",
    "                    current_frame = int(file_params[2])\n",
    "                    tmp_dataset.append(current_frame) #3\n",
    "\n",
    "                    ## Get frame difference\n",
    "                    if last_frame == 0:\n",
    "                        tmp_dataset.append(0)\n",
    "                    else:\n",
    "                        tmp_dataset.append(current_frame - last_frame)\n",
    "                    last_frame = current_frame\n",
    "                    ## Get coordinates\n",
    "\n",
    "                    tmp_dataset.append( [int( file_params[3]),int(file_params[4])] )\n",
    "                    ## Get time difference from last frame\n",
    "                    dataset.append([tmp_dataset])\n",
    "                else:\n",
    "                    none_count += 1\n",
    "                count += 1\n",
    "            if count == 5:\n",
    "                print(\"Breaking, count == 5\")\n",
    "                break\n",
    "        print(\"None count: \", none_count, \" | Images loaded: \", count)\n",
    "        return np.array(dataset)\n",
    "       \n",
    "    def conv2d(self, tf_in, W, b):\n",
    "        conv = tf.nn.conv2d(tf_in, W, strides=[1,1,1,1], padding='SAME')\n",
    "        conv_with_b = tf.nn.bias_add(conv, b)\n",
    "        conv_out = tf.nn.relu(conv_with_b)\n",
    "        return conv_out\n",
    "\n",
    "    def maxpool2d(self,tf_in):\n",
    "        #                          size of window    moment of window\n",
    "        return tf.nn.max_pool(tf_in, ksize=[1,2,2,1], strides=[1,2,2,1],padding='SAME')\n",
    "    \n",
    "    def rnn_load_data(self):\n",
    "        self.x = old_load_labels()\n",
    "        #self.x = self.load_labels()\n",
    "        np.random.shuffle(self.x)\n",
    "        self.train_data, self.test_data = predictor.split_arr(self.x, 0.25)\n",
    "        print(\"Traing_data count: \", len(self.train_data))\n",
    "        print(\"Test_data count: \", len(self.test_data))\n",
    "        self.hm_epochs = 3\n",
    "\n",
    "    def rnn_model(self):\n",
    "        # 5 x 5, 3 input, produces 32 features\n",
    "        self.weights = {'W_conv1':tf.Variable(tf.random_normal([5,5,3,32]),name='W_conv1'),\n",
    "                        'W_conv2':tf.Variable(tf.random_normal([5,5,32,64]),name='W_conv2'),\n",
    "                        'W_fc':tf.Variable(tf.random_normal([6*6*64, 1024]),name='W_fc'),\n",
    "                        'W_out':tf.Variable(tf.random_normal([1024, self.n_classes]),name='W_out')}\n",
    "        self.biases = {'b_conv1':tf.Variable(tf.random_normal([32]),name='b_conv1'),\n",
    "                       'b_conv2':tf.Variable(tf.random_normal([64]),name='b_conv2'),\n",
    "                       'b_fc':tf.Variable(tf.random_normal([1024]),name='b_fc'),\n",
    "                       'b_out':tf.Variable(tf.random_normal([self.n_classes]),name='b_out')}\n",
    "        x_tf = tf.reshape(self.x, shape=[-1,24,24,3])\n",
    "        conv1 = self.maxpool2d(self.conv2d(x_tf, self.weights['W_conv1'], self.biases['b_conv1']))\n",
    "        conv2 = self.maxpool2d(self.conv2d(conv1, self.weights['W_conv2'], self.biases['b_conv2']))\n",
    "        fc = tf.reshape(conv2,[-1,6*6*64])\n",
    "        fc = tf.nn.relu(tf.matmul(fc, self.weights['W_fc']) + self.biases['b_fc'])\n",
    "        fc = tf.nn.dropout(fc, self.keep_rate)\n",
    "        output = tf.matmul(fc, self.weights['W_out']) + self.biases['b_out']\n",
    "        return output\n",
    "    \n",
    "    def rnn_train(self, zero_catch=0, time_stamp=False):    \n",
    "        prediction = self.rnn_model()\n",
    "        cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=self.y) )\n",
    "        optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            loss_plot = []\n",
    "            hm_zeros = 0\n",
    "            for epoch in range(hm_epochs):\n",
    "                epoch_loss = 0\n",
    "\n",
    "                for i in range(len(self.train_data)):\n",
    "                    batch_x = self.train_data[i][0]\n",
    "                    batch_y = self.train_data[i][1]\n",
    "                    _, c = sess.run([optimizer, cost], feed_dict = {self.x: batch_x, self.y: batch_y})\n",
    "                    epoch_loss += c\n",
    "                loss_plot.append(epoch_loss)\n",
    "                print('Epoch: ', epoch, ' completed out of: ', hm_epochs, ' loss: ', epoch_loss)\n",
    "                if (zero_catch > 0) and (epoch_loss == 0):\n",
    "                    hm_zeros += 1\n",
    "                    if hm_zeros == zero_catch:\n",
    "                        print(\"Reached zero catch of: \", zero_catch)\n",
    "                        break\n",
    "                elif (epoch_loss != 0):\n",
    "                    hm_zeros = 0\n",
    "\n",
    "            # Check how good model is\n",
    "            correct = tf.equal (tf.argmax(prediction,-1), tf.argmax(self.y,-1))\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "            acc = false_pos = false_neg = true_pos = true_neg = 0\n",
    "            for i in range(len(self.test_data)):\n",
    "                curr_acc = accuracy.eval({self.x: self.test_data[i,0], self.y: self.test_data[i,1]})\n",
    "                true_result =  self.test_data[i,1][0]\n",
    "                if true_result == 1 and curr_acc == 0:\n",
    "                    false_neg += 1\n",
    "                elif true_result == 0 and curr_acc == 0:\n",
    "                    false_pos += 1\n",
    "                elif true_result == 1 and curr_acc == 1:\n",
    "                    true_pos += 1\n",
    "                elif true_result == 0 and curr_acc == 1:\n",
    "                    true_neg += 1\n",
    "                acc += curr_acc\n",
    "\n",
    "            #Save model to file\n",
    "            location = 'C:/Users/joear/OneDrive - Imperial College London/General/Code/Python/EDP/cnn_model/'\n",
    "            if time_stamp: save_path = saver.save(sess, location + \"current_model\")\n",
    "            else: save_path = saver.save(sess, location + \"current_model_\" + frame_stamp())\n",
    "            print(\"Model saved in path: %s\" % save_path)\n",
    "\n",
    "            print(\"=======================================\")\n",
    "            print(\"Accuracy: \", acc/len(self.test_data)*100)\n",
    "            print(\"Tests: \", len(self.test_data))\n",
    "            print(\"Positive Sample: \", true_pos + false_neg)\n",
    "            print(\"Negative Sample: \", false_pos + true_neg)\n",
    "            print(\"Incorrect: \", false_pos + false_neg)\n",
    "            print(\"--------------------------------------\")\n",
    "            print(\"False Positives: \", false_pos)\n",
    "            print(\"False Negatives: \", false_neg)\n",
    "            print(\"True  Positives: \", true_pos)\n",
    "            print(\"True  Negatives: \", true_neg)\n",
    "            plt.plot(loss_plot)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None count:  14\n",
      "Traing_data count:  1847\n",
      "Test_data count:  616\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got array([[[  5.,   2.,   4.],\n        [  8.,   6.,   6.],\n        [  7.,   5.,   4.],\n        ..., \n        [ 16.,   7.,  10.],\n        [ 16.,   7.,  10.],\n        [ 15.,   5.,  11.]],\n\n       [[  9.,   7.,   7.],\n        [  6.,   4.,   3.],\n        [  5.,   3.,   2.],\n        ..., \n        [ 15.,   7.,   8.],\n        [ 14.,   5.,   8.],\n        [ 13.,   4.,   7.]],\n\n       [[  7.,   5.,   4.],\n        [  5.,   3.,   2.],\n        [  6.,   5.,   1.],\n        ..., \n        [ 17.,   9.,   9.],\n        [ 16.,   8.,   9.],\n        [ 15.,   7.,   8.]],\n\n       ..., \n       [[ 19.,  14.,  13.],\n        [ 19.,  14.,  13.],\n        [ 20.,  15.,  14.],\n        ..., \n        [ 18.,  10.,  10.],\n        [ 18.,  10.,  10.],\n        [ 19.,  11.,  11.]],\n\n       [[ 17.,  12.,  11.],\n        [ 17.,  12.,  11.],\n        [ 17.,  12.,  11.],\n        ..., \n        [ 19.,  11.,  11.],\n        [ 19.,  11.,  11.],\n        [ 20.,  12.,  12.]],\n\n       [[ 14.,   9.,   8.],\n        [ 14.,   9.,   8.],\n        [ 15.,  10.,   9.],\n        ..., \n        [ 19.,  11.,  11.],\n        [ 20.,  12.,  12.],\n        [ 21.,  13.,  13.]]])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-c9715053b482>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnnClassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_load_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero_catch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_stamp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-34-d7f4748c1770>\u001b[0m in \u001b[0;36mrnn_train\u001b[1;34m(self, zero_catch, time_stamp)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrnn_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzero_catch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_stamp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-d7f4748c1770>\u001b[0m in \u001b[0;36mrnn_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    126\u001b[0m                        \u001b[1;34m'b_fc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b_fc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                        'b_out':tf.Variable(tf.random_normal([self.n_classes]),name='b_out')}\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mx_tf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxpool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W_conv1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b_conv1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mconv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxpool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W_conv2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b_conv2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python364\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(tensor, shape, name)\u001b[0m\n\u001b[0;32m   3935\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3936\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 3937\u001b[1;33m         \"Reshape\", tensor=tensor, shape=shape, name=name)\n\u001b[0m\u001b[0;32m   3938\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3939\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python364\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    511\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    514\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m               raise TypeError(\n",
      "\u001b[1;32mc:\\program files\\python364\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    508\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[0;32m    511\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python364\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[0;32m    924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 926\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python364\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    227\u001b[0m                                          as_ref=False):\n\u001b[0;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python364\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[0;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m--> 208\u001b[1;33m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[0;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[1;32mc:\\program files\\python364\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    481\u001b[0m     raise TypeError(\"Element type not supported in TensorProto: %s\" %\n\u001b[0;32m    482\u001b[0m                     numpy_dtype.name)\n\u001b[1;32m--> 483\u001b[1;33m   \u001b[0mappend_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_proto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python364\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mSlowAppendObjectArrayToTensorProto\u001b[1;34m(tensor_proto, proto_values)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mSlowAppendObjectArrayToTensorProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_proto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[0mtensor_proto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mSlowAppendBoolArrayToTensorProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_proto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python364\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mSlowAppendObjectArrayToTensorProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_proto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[0mtensor_proto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mSlowAppendBoolArrayToTensorProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_proto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python364\\lib\\site-packages\\tensorflow\\python\\util\\compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[1;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[1;32m---> 65\u001b[1;33m                     (bytes_or_text,))\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected binary or unicode string, got array([[[  5.,   2.,   4.],\n        [  8.,   6.,   6.],\n        [  7.,   5.,   4.],\n        ..., \n        [ 16.,   7.,  10.],\n        [ 16.,   7.,  10.],\n        [ 15.,   5.,  11.]],\n\n       [[  9.,   7.,   7.],\n        [  6.,   4.,   3.],\n        [  5.,   3.,   2.],\n        ..., \n        [ 15.,   7.,   8.],\n        [ 14.,   5.,   8.],\n        [ 13.,   4.,   7.]],\n\n       [[  7.,   5.,   4.],\n        [  5.,   3.,   2.],\n        [  6.,   5.,   1.],\n        ..., \n        [ 17.,   9.,   9.],\n        [ 16.,   8.,   9.],\n        [ 15.,   7.,   8.]],\n\n       ..., \n       [[ 19.,  14.,  13.],\n        [ 19.,  14.,  13.],\n        [ 20.,  15.,  14.],\n        ..., \n        [ 18.,  10.,  10.],\n        [ 18.,  10.,  10.],\n        [ 19.,  11.,  11.]],\n\n       [[ 17.,  12.,  11.],\n        [ 17.,  12.,  11.],\n        [ 17.,  12.,  11.],\n        ..., \n        [ 19.,  11.,  11.],\n        [ 19.,  11.,  11.],\n        [ 20.,  12.,  12.]],\n\n       [[ 14.,   9.,   8.],\n        [ 14.,   9.,   8.],\n        [ 15.,  10.,   9.],\n        ..., \n        [ 19.,  11.,  11.],\n        [ 20.,  12.,  12.],\n        [ 21.,  13.,  13.]]])"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    predictor = rnnClassify()\n",
    "    predictor.rnn_load_data()\n",
    "    predictor.rnn_train(zero_catch=0, time_stamp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
