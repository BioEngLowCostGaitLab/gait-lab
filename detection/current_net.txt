def Net(x):
    fSize = 32
    # Hidden layer with RELU activation
    x = tf.layers.conv2d(x, fSize, 3, strides=(2,2),
    activation=tf.nn.relu)
    x = tf.layers.conv2d(x, 2 * fSize, 3, strides=(2,2),
    activation=tf.nn.relu)
    x = tf.layers.conv2d(x, 4 * fSize, 3, strides=(1,1),
    activation=tf.nn.relu)
    x = tf.layers.conv2d(x, 1, 3, strides=(1,1),
    activation=None)
    x = tf.nn.sigmoid(x)
    return x
