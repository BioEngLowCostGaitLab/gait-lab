{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import analyse\n",
    "from datetime import datetime as dt\n",
    "from cnn_load_data import load_labels as old_load_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_stamp():\n",
    "    current = dt.now()\n",
    "    out_str = (str(current.year) + str(current.month) + str(current.day) + \"_\" + \n",
    "               str(current.hour) + str(current.minute) + str(current.second) + \"_\" +\n",
    "               str(current.microsecond))\n",
    "    return out_str\n",
    "\n",
    "def pad(arr):\n",
    "    r = np.zeros((24,24,3))\n",
    "    r[:arr.shape[0],:arr.shape[1],:arr.shape[2]] = arr\n",
    "    return r\n",
    "\n",
    "def split_arr(arr, percent):\n",
    "    position = int(len(arr) * (1-percent))\n",
    "    train_data = arr[:position]\n",
    "    test_data = arr[position:]\n",
    "    return train_data, test_data\n",
    "\n",
    "def load_labels():\n",
    "    fdir = \"seq_labels\"\n",
    "    dataset = []\n",
    "    x = 0\n",
    "    none_count = 0\n",
    "    last_frame = 0\n",
    "    last_seq = 0\n",
    "    for file in os.listdir(fdir):\n",
    "        if file.endswith(\".jpg\"):\n",
    "            img = cv.imread(os.path.join(fdir,file), cv.IMREAD_UNCHANGED)\n",
    "            if not img is None:\n",
    "                img = pad(img)\n",
    "                file_params = file.split(\"_\")                \n",
    "                ## Check if labeled as ball\n",
    "                tmp_dataset = []\n",
    "                if file_params[0] == 0:    \n",
    "                    tmp_dataset.append(img) #0\n",
    "                    tmp_dataset.append(np.array([0,1])) #1\n",
    "                else:\n",
    "                    tmp_dataset.append(img) #0\n",
    "                    tmp_dataset.append(np.array([1,0])) #1\n",
    "                ## Get seqence ID\n",
    "                current_seq = int(file_params[1])\n",
    "                tmp_dataset.append(current_seq) #2\n",
    "                if current_seq != last_seq:\n",
    "                    last_frame = 0\n",
    "                    last_seq = current_seq\n",
    "                \n",
    "                ## Get frame number (Will decide if frame number or difference is more useful later on)\n",
    "                print(file_params[2])\n",
    "                current_frame = int(file_params[2])\n",
    "                tmp_dataset.append(current_frame) #3\n",
    "                \n",
    "                ## Get frame difference\n",
    "                if last_frame == 0:\n",
    "                    tmp_dataset.append(0)\n",
    "                else:\n",
    "                    tmp_dataset.append(current_frame - last_frame)\n",
    "                last_frame = current_frame\n",
    "                ## Get coordinates\n",
    "                \n",
    "                tmp_dataset.append( [int( file_params[3]),int(file_params[4])] )\n",
    "                \n",
    "                ## Get time difference from last frame\n",
    "                dataset.append([tmp_dataset])\n",
    "            else:\n",
    "                none_count += 1\n",
    "            x += 1\n",
    "        if x == 5:\n",
    "            break\n",
    "    print(\"None count: \", none_count, \" | Images loaded: \", x)\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def maxpool2d(x):\n",
    "    #                          size of window    moment of window\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "def cnn_model(x):\n",
    "    # 5 x 5, 1 input, produces 32 features\n",
    "    weights = {'W_conv1':tf.Variable(tf.random_normal([5,5,3,32])),\n",
    "               'W_conv2':tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "               'W_fc':tf.Variable(tf.random_normal([6*6*64, 1024])),\n",
    "               'out':tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "    \n",
    "    biases = {'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "              'b_conv2':tf.Variable(tf.random_normal([64])),\n",
    "              'b_fc':tf.Variable(tf.random_normal([1024])),\n",
    "              'out':tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    x = tf.reshape(x, shape=[-1,24,24,3])\n",
    "    \n",
    "    conv1 = tf.nn.relu(conv2d(x, weights['W_conv1']) + biases['b_conv1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv2d(conv1, weights['W_conv2']) + biases['b_conv2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "    \n",
    "    fc = tf.reshape(conv2,[-1,6*6*64])\n",
    "    fc = tf.nn.relu(tf.matmul(fc, weights['W_fc']) + biases['b_fc'])\n",
    "    \n",
    "    fc = tf.nn.dropout(fc,keep_rate)\n",
    "    \n",
    "    output = tf.matmul(fc, weights['out']) + biases['out']\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_train(x, train_data, test_data, zero_catch=0, time_stamp = False):    \n",
    "    prediction = cnn_model(x)\n",
    "    cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        loss_plot = []\n",
    "        hm_zeros = 0\n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            \n",
    "            for i in range(len(train_data)):\n",
    "                batch_x = train_data[i][0]\n",
    "                batch_y = train_data[i][1]\n",
    "                _, c = sess.run([optimizer, cost], feed_dict = {x: batch_x, y: batch_y})\n",
    "                epoch_loss += c\n",
    "            loss_plot.append(epoch_loss)\n",
    "            print('Epoch: ', epoch, ' completed out of: ', hm_epochs, ' loss: ', epoch_loss)\n",
    "            if (zero_catch > 0) and (epoch_loss == 0):\n",
    "                hm_zeros += 1\n",
    "                if hm_zeros == zero_catch:\n",
    "                    print(\"Reached zero catch of: \", zero_catch)\n",
    "                    break\n",
    "            elif (epoch_loss != 0):\n",
    "                hm_zeros = 0\n",
    "                \n",
    "        # Check how good model is\n",
    "        correct = tf.equal (tf.argmax(prediction,-1), tf.argmax(y,-1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "        acc = false_pos = false_neg = true_pos = true_neg = 0\n",
    "        for i in range(len(test_data)):\n",
    "            curr_acc = accuracy.eval({x:test_data[i,0], y:test_data[i,1]})\n",
    "            true_result =  test_data[i,1][0]\n",
    "            if true_result == 1 and curr_acc == 0:\n",
    "                false_neg += 1\n",
    "            elif true_result == 0 and curr_acc == 0:\n",
    "                false_pos += 1\n",
    "            elif true_result == 1 and curr_acc == 1:\n",
    "                true_pos += 1\n",
    "            elif true_result == 0 and curr_acc == 1:\n",
    "                true_neg += 1\n",
    "            acc += curr_acc\n",
    "        \n",
    "        #Save model to file\n",
    "        location = 'C:/Users/joear/OneDrive - Imperial College London/General/Code/Python/EDP/cnn_model/'\n",
    "        if time_stamp: save_path = saver.save(sess, location + \"current_model\")\n",
    "        else: save_path = saver.save(sess, location + \"current_model_\" + frame_stamp())\n",
    "        print(\"Model saved in path: %s\" % save_path)\n",
    "        \n",
    "        print(\"=======================================\")\n",
    "        print(\"Accuracy: \", acc/len(test_data)*100)\n",
    "        print(\"Tests: \", len(test_data))\n",
    "        print(\"Positive Sample: \", true_pos + false_neg)\n",
    "        print(\"Negative Sample: \", false_pos + true_neg)\n",
    "        print(\"Incorrect: \", false_pos + false_neg)\n",
    "        print(\"--------------------------------------\")\n",
    "        print(\"False Positives: \", false_pos)\n",
    "        print(\"False Negatives: \", false_neg)\n",
    "        print(\"True  Positives: \", true_pos)\n",
    "        print(\"True  Negatives: \", true_neg)\n",
    "        plt.plot(loss_plot)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None count:  14\n",
      "Traing_data count:  1847\n",
      "Test_data count:  616\n",
      "Epoch:  0  completed out of:  25  loss:  988621867.625\n",
      "Epoch:  1  completed out of:  25  loss:  279771596.938\n",
      "Epoch:  2  completed out of:  25  loss:  82340358.375\n",
      "Epoch:  3  completed out of:  25  loss:  71327439.5625\n",
      "Epoch:  4  completed out of:  25  loss:  9682342.34375\n",
      "Epoch:  5  completed out of:  25  loss:  60196820.875\n",
      "Epoch:  6  completed out of:  25  loss:  20377070.875\n",
      "Epoch:  7  completed out of:  25  loss:  17564739.3438\n",
      "Epoch:  8  completed out of:  25  loss:  22862100.0\n",
      "Epoch:  9  completed out of:  25  loss:  1218835.0\n",
      "Epoch:  10  completed out of:  25  loss:  384456.15625\n",
      "Epoch:  11  completed out of:  25  loss:  8102937.8125\n",
      "Epoch:  12  completed out of:  25  loss:  23689148.5625\n",
      "Epoch:  13  completed out of:  25  loss:  4443676.125\n",
      "Epoch:  14  completed out of:  25  loss:  5495322.96875\n",
      "Epoch:  15  completed out of:  25  loss:  542038.5\n",
      "Epoch:  16  completed out of:  25  loss:  0.0\n",
      "Epoch:  17  completed out of:  25  loss:  0.0\n",
      "Epoch:  18  completed out of:  25  loss:  13787732.0625\n",
      "Epoch:  19  completed out of:  25  loss:  6263105.0\n",
      "Epoch:  20  completed out of:  25  loss:  6280229.84375\n",
      "Epoch:  21  completed out of:  25  loss:  0.0\n",
      "Epoch:  22  completed out of:  25  loss:  10149790.75\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = old_load_labels()\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    train_data, test_data = split_arr(data, 0.25)\n",
    "    print(\"Traing_data count: \", len(train_data))\n",
    "    print(\"Test_data count: \", len(test_data))\n",
    "\n",
    "    n_classes = 2\n",
    "    hm_epochs = 25\n",
    "\n",
    "    x = tf.placeholder('float',[24,24,3])\n",
    "    y = tf.placeholder('float')\n",
    "\n",
    "    keep_rate = 0.8\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "    cnn_train(x, train_data, test_data, zero_catch=0, time_stamp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Template code to refer to later\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "\n",
    "\n",
    "class SeriesPredictor:\n",
    "\n",
    "    def __init__(self, input_dim, seq_size, hidden_dim=10):\n",
    "        # Hyperparameters\n",
    "        self.input_dim = input_dim\n",
    "        self.seq_size = seq_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Weight variables and input placeholders\n",
    "        self.W_out = tf.Variable(tf.random_normal([hidden_dim, 1]), name='W_out')\n",
    "        self.b_out = tf.Variable(tf.random_normal([1]), name='b_out')\n",
    "        self.x = tf.placeholder(tf.float32, [None, seq_size, input_dim])\n",
    "        self.y = tf.placeholder(tf.float32, [None, seq_size])\n",
    "\n",
    "        # Cost optimizer\n",
    "        self.cost = tf.reduce_mean(tf.square(self.model() - self.y))\n",
    "        self.train_op = tf.train.AdamOptimizer().minimize(self.cost)\n",
    "\n",
    "        # Auxiliary ops\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "    def model(self):\n",
    "        \"\"\"\n",
    "        :param x: inputs of size [T, batch_size, input_size]\n",
    "        :param W: matrix of fully-connected output layer weights\n",
    "        :param b: vector of fully-connected output layer biases\n",
    "        \"\"\"\n",
    "        cell = rnn_cell.BasicLSTMCell(self.hidden_dim, reuse=tf.get_variable_scope().reuse)\n",
    "        outputs, states = rnn.dynamic_rnn(cell, self.x, dtype=tf.float32)\n",
    "        num_examples = tf.shape(self.x)[0]\n",
    "        W_repeated = tf.tile(tf.expand_dims(self.W_out, 0), [num_examples, 1, 1])\n",
    "        out = tf.batch_matmul(outputs, W_repeated) + self.b_out\n",
    "        out = tf.squeeze(out)\n",
    "        return out\n",
    "\n",
    "    def train(self, train_x, train_y):\n",
    "        with tf.Session() as sess:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            for i in range(1000):\n",
    "                _, mse = sess.run([self.train_op, self.cost], feed_dict={self.x: train_x, self.y: train_y})\n",
    "                if i % 100 == 0:\n",
    "                    print(i, mse)\n",
    "            save_path = self.saver.save(sess, 'model.ckpt')\n",
    "            print('Model saved to {}'.format(save_path))\n",
    "\n",
    "    def test(self, test_x):\n",
    "        with tf.Session() as sess:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            self.saver.restore(sess, 'model.ckpt')\n",
    "            output = sess.run(self.model(), feed_dict={self.x: test_x})\n",
    "            print(output)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    predictor = SeriesPredictor(input_dim=1, seq_size=4, hidden_dim=10)\n",
    "    train_x = [[[1], [2], [5], [6]],\n",
    "               [[5], [7], [7], [8]],\n",
    "               [[3], [4], [5], [7]]]\n",
    "    train_y = [[1, 3, 7, 11],\n",
    "               [5, 12, 14, 15],\n",
    "               [3, 7, 9, 12]]\n",
    "    predictor.train(train_x, train_y)\n",
    "\n",
    "    test_x = [[[1], [2], [3], [4]],  # 1, 3, 5, 7\n",
    "              [[4], [5], [6], [7]]]  # 4, 9, 11, 13\n",
    "    predictor.test(test_x)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
